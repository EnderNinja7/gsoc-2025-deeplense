{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22413,
     "status": "ok",
     "timestamp": 1742465599242,
     "user": {
      "displayName": "Dhruv Srivastava",
      "userId": "12056314543051163599"
     },
     "user_tz": 300
    },
    "id": "vRM2kxST8KJZ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GSoC 2025 Internship Application Task - 1\n",
    "Author: Dhruv Srivastava\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Import dependencies\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define Dataset Class\"\"\"\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.class_names = ['no', 'sphere', 'vort']\n",
    "        \n",
    "        print(f\"Loading dataset from: {data_dir}\")\n",
    "        print(f\"Looking for classes: {self.class_names}\")\n",
    "        \n",
    "        for idx, class_name in enumerate(self.class_names):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            print(f\"Processing class: {class_name} (index: {idx})\")\n",
    "            \n",
    "            # Check if directory exists\n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"[ERROR] Directory not found: {class_dir}\")\n",
    "                continue\n",
    "            \n",
    "            files = os.listdir(class_dir)\n",
    "            print(f\"Found {len(files)} files in {class_name} directory\")\n",
    "            \n",
    "            for file_name in files:\n",
    "                if file_name.endswith('.npy'):\n",
    "                    file_path = os.path.join(class_dir, file_name)\n",
    "                    image = np.load(file_path)\n",
    "                    \n",
    "                    # Debug image loading\n",
    "                    print(f\"Loading image: {file_name}\")\n",
    "                    print(f\"Image shape: {image.shape}\")\n",
    "                    \n",
    "                    # Ensure the image is 3-channel (RGB-like)\n",
    "                    if len(image.shape) == 2:\n",
    "                        image = np.stack([image]*3, axis=0)\n",
    "                        print(\"Converted 2D image to 3-channel\")\n",
    "                    elif len(image.shape) == 3 and image.shape[0] == 1:\n",
    "                        image = np.repeat(image, 3, axis=0)\n",
    "                        print(\"Converted single-channel image to 3-channel\")\n",
    "                    \n",
    "                    self.data.append(torch.tensor(image, dtype=torch.float32))\n",
    "                    self.labels.append(idx)\n",
    "        \n",
    "        print(f\"Total images loaded: {len(self.data)}\")\n",
    "        print(f\"Distribution of classes: {np.unique(self.labels, return_counts=True)}\")\n",
    "        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "    \n",
    "# Data Directories\n",
    "train_dir = '../dataset/dataset/train'\n",
    "val_dir = '../dataset/dataset/val'\n",
    "    \n",
    "print(f\"Training Directory: {train_dir}\")\n",
    "print(f\"Validation Directory: {val_dir}\")\n",
    "    \n",
    "# Create Datasets and Dataloaders\n",
    "train_dataset = MyDataset(train_dir)\n",
    "val_dataset = MyDataset(val_dir)\n",
    "    \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Number of Training Batches: {len(train_loader)}\")\n",
    "print(f\"Number of Validation Batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified ResNet18 for Lens Classification\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        print(\"Initializing Modified ResNet18\")\n",
    "        \n",
    "        # Load ResNet18\n",
    "        resnet = resnet18(pretrained=True)\n",
    "        \n",
    "        # Modify first conv layer to accept single-channel input\n",
    "        resnet.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Replace the last layer\n",
    "        num_features = resnet.fc.in_features\n",
    "        resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.model = resnet\n",
    "        \n",
    "        print(f\"Model architecture: {self.model}\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training and Evaluation\"\"\"\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Training on device: {device}\")\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    best_val_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n===== Epoch {epoch+1}/{num_epochs} =====\")\n",
    "        \n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Debug information\n",
    "            print(f\"Training Batch {batch_idx+1}/{len(train_loader)}\")\n",
    "            print(f\"Batch images shape: {images.shape}\")\n",
    "            print(f\"Batch labels: {labels}\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            \n",
    "            batch_accuracy = (predicted == labels).float().mean().item()\n",
    "            print(f\"Batch Loss: {loss.item():.4f}, Batch Accuracy: {batch_accuracy:.4f}\")\n",
    "        \n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # Debug validation information\n",
    "                print(f\"Validation Batch {batch_idx+1}/{len(val_loader)}\")\n",
    "                print(f\"Batch images shape: {images.shape}\")\n",
    "                print(f\"Batch labels: {labels}\")\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                \n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                all_preds.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                \n",
    "                batch_accuracy = (predicted == labels).float().mean().item()\n",
    "                print(f\"Validation Batch Loss: {loss.item():.4f}, Validation Batch Accuracy: {batch_accuracy:.4f}\")\n",
    "        \n",
    "        \n",
    "        train_accuracy = train_correct / len(train_loader.dataset)\n",
    "        val_accuracy = val_correct / len(val_loader.dataset)\n",
    "        \n",
    "        # Epoch-level metrics\n",
    "        print(f'\\n[SUMMARY] Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "        print(f'Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), 'lens_classifier_model.pth')\n",
    "            print(f\"New best model saved with validation accuracy: {best_val_accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\nTraining Complete!\")\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "model = Net(num_classes=3)\n",
    "    \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "print(\"Optimizer: Adam\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "    \n",
    "# Train Model\n",
    "all_preds, all_labels = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ROC Curve Plotting Function\"\"\"\n",
    "def plot_roc_curve(all_preds, all_labels):\n",
    "    print(\"Generating ROC Curve\")\n",
    "    \n",
    "    # Convert predictions and labels to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_classes = 3\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve((all_labels == i).astype(int), all_preds[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        print(f\"Class {i} ROC AUC: {roc_auc[i]:.4f}\")\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['blue', 'red', 'green']\n",
    "    class_names = ['No Substructure', 'Sphere Substructure', 'Vortex Substructure']\n",
    "    \n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, \n",
    "                 label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"ROC Curve saved as roc_curve.png\")\n",
    "\n",
    "\n",
    "plot_roc_curve(all_preds, all_labels)\n",
    "    \n",
    "print(\"Training and Evaluation Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMIM+amG+z9BkW+nJwvc9qa",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
